{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 20:57:14.691846: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-05 20:57:14.850413: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-05 20:57:15.141985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-05 20:57:15.494637: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-05 20:57:15.540460: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-05 20:57:15.875158: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-05 20:57:21.477331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1 `Usefull function to create input pipe line with tensorflow. `\n",
    "\n",
    "- How to convert python list into TFdata.\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorDataset element_spec=TensorSpec(shape=(8,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# python list to TFdataset: \n",
    "\n",
    "daily_sale_number = [21,22,-108,31,-1,32,34,31]\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensors(daily_sale_number)\n",
    "\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.int32, name=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data specification :\n",
    "\n",
    "tf_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sale_number)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "# 1.2 : `How to print the tensorData.`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 21:18:22.148603: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# print tensor with for loop\n",
    "\n",
    "for sale in tf_dataset:\n",
    "    print(sale)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n",
      "\n",
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n",
      "\n",
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 21:23:08.056633: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert tensor in numpy and print it \n",
    "\n",
    "for sale in tf_dataset:\n",
    "    print(sale.numpy())\n",
    "    \n",
    "\n",
    "print()\n",
    "\n",
    "for sale in tf_dataset.as_numpy_iterator():\n",
    "    print(sale)\n",
    "    \n",
    "\n",
    "print()\n",
    "\n",
    "# take some number: \n",
    "for sale in tf_dataset.take(3):\n",
    "    print(sale)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1.3 `apply filter function: `\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# filter into the TFdatast:\n",
    "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
    "for i in tf_dataset:\n",
    "    print(i.numpy())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1.4  `Multipy something with each of the elemnet in TFdataset. `\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21\n",
      "-22\n",
      "-31\n",
      "-32\n",
      "-34\n",
      "-31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# access all of the element without for loop:\n",
    "\n",
    "tf_dataset = tf_dataset.map(lambda x: x * (-1))\n",
    "for i in tf_dataset:\n",
    "    print(i.numpy()) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1.5 `Batching dataset: `\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21\n",
      "-22\n",
      "-31\n",
      "-32\n",
      "-34\n",
      "-31\n"
     ]
    }
   ],
   "source": [
    "# without batching: \n",
    "for i in tf_dataset:\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-21 -22], shape=(2,), dtype=int32)\n",
      "tf.Tensor([-31 -32], shape=(2,), dtype=int32)\n",
      "tf.Tensor([-34 -31], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# batch with size: 2 \n",
    "for i in tf_dataset.batch(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-21 -22 -31], shape=(3,), dtype=int32)\n",
      "tf.Tensor([-32 -34 -31], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# batch with size: 3 \n",
    "for i in tf_dataset.batch(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1.6 `Shuffle tensorData set: `\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Imagine, you have a dataset: `[1, 2, 3, 4, 5, 6]`, then:\n",
    "\n",
    "---\n",
    "\n",
    "### How `ds.shuffle(buffer_size)` Works:\n",
    "\n",
    "`dataset.shuffle(buffer_size=3)` will allocate a buffer of size 3 for picking random entries. This buffer will be connected to the source dataset. We could imagine it like this:\n",
    "\n",
    "```\n",
    "Random buffer\n",
    "   |\n",
    "   |   Source dataset where all other elements live\n",
    "   |         |\n",
    "   ↓         ↓\n",
    "[1,2,3] <= [4,5,6]\n",
    "```\n",
    "\n",
    "Let's assume that entry `2` was taken from the random buffer. Free space is filled by the next element from the source buffer, that is `4`:\n",
    "\n",
    "```\n",
    "2 <= [1,3,4] <= [5,6]\n",
    "```\n",
    "\n",
    "We continue reading till nothing is left:\n",
    "\n",
    "```\n",
    "1 <= [3,4,5] <= [6]\n",
    "5 <= [3,4,6] <= []\n",
    "3 <= [4,6]   <= []\n",
    "6 <= [4]     <= []\n",
    "4 <= []      <= []\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### How `ds.repeat()` Works:\n",
    "\n",
    "As soon as all the entries are read from the dataset and you try to read the next element, the dataset will throw an error. That's where `ds.repeat()` comes into play. It will re-initialize the dataset, making it again like this:\n",
    "\n",
    "```\n",
    "[1,2,3] <= [4,5,6]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### What `ds.batch()` Produces:\n",
    "\n",
    "The `ds.batch()` will take the first `batch_size` entries and make a batch out of them. So, a batch size of `3` for our example dataset will produce two batch records:\n",
    "\n",
    "```\n",
    "[2,1,5]\n",
    "[3,6,4]\n",
    "```\n",
    "\n",
    "As we have a `ds.repeat()` before the batch, the generation of the data will continue. But the order of the elements will be different, due to the `ds.random()`. What should be taken into account is that `6` will never be present in the first batch, due to the size of the random buffer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# now, let's try with an example: \n",
    "\n",
    "sample_data = [1,2,3,4,5,6]\n",
    "ds = tf.data.Dataset.from_tensor_slices(sample_data)\n",
    "\n",
    "\n",
    "# print tfData:\n",
    "for i in ds:\n",
    "    print(i.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# now use shuffle:\n",
    "for i in ds.shuffle(buffer_size=3):\n",
    "    print(i.numpy())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## `1.3, 1.4, 1.5, 1.6 apply all the transformation in a single line:` \n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7ccb685f4d60> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ccb685f4d60>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 2\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ccb685f4d60> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ccb685f4d60>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 2\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7ccb685f6d40> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ccb685f6d40>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 2\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ccb685f6d40> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ccb685f6d40>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 2\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([42 44 64], shape=(3,), dtype=int32)\n",
      "tf.Tensor([68 62 62], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sale_number)\n",
    "\n",
    "new_dataset = tf_dataset.filter(lambda x: x>0).map(lambda x: x*2).shuffle(3).batch(3)\n",
    "\n",
    "for i in new_dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([44 42 64], shape=(3,), dtype=int32)\n",
      "tf.Tensor([68 62 62], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# __________ use this to avoid warning __________ : \n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def process_data():\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sale_number)\n",
    "    new_dataset = tf_dataset.filter(lambda x: x > 0).map(lambda x: x * 2).shuffle(3).batch(3)\n",
    "    \n",
    "    for i in new_dataset:\n",
    "        print(i)\n",
    "\n",
    "process_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
